%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tufte-Style Book (Minimal Template)
% LaTeX Template
% Version 1.0 (5/1/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
% IMPORTANT NOTE:
% In addition to running BibTeX to compile the reference list from the .bib
% file, you will need to run MakeIndex to compile the index at the end of the
% document.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{tufte-book} % Use the tufte-book class which in turn uses the tufte-common class

\hypersetup{colorlinks} % Comment this line if you don't wish to have colored links

\usepackage{microtype} % Improves character and word spacing

\usepackage{lipsum} % Inserts dummy text

\usepackage{booktabs} % Better horizontal rules in tables

\usepackage{graphicx} % Needed to insert images into the document
\graphicspath{{graphics/}} % Sets the default location of pictures
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio} % Improves figure scaling

\usepackage{fancyvrb} % Allows customization of verbatim environments
\fvset{fontsize=\normalsize} % The font size of all verbatim text can be changed here

\newcommand{\hangp}[1]{\makebox[0pt][r]{(}#1\makebox[0pt][l]{)}} % New command to create parentheses around text in tables which take up no horizontal space - this improves column spacing
\newcommand{\hangstar}{\makebox[0pt][l]{*}} % New command to create asterisks in tables which take up no horizontal space - this improves column spacing

\usepackage{xspace} % Used for printing a trailing space better than using a tilde (~) using the \xspace command

\newcommand{\monthyear}{\ifcase\month\or January\or February\or March\or April\or May\or June\or July\or August\or September\or October\or November\or December\fi\space\number\year} % A command to print the current month and year

\newcommand{\openepigraph}[2]{ % This block sets up a command for printing an epigraph with 2 arguments - the quote and the author
\begin{fullwidth}
\sffamily\large
\begin{doublespace}
\noindent\allcaps{#1}\\ % The quote
\noindent\allcaps{#2} % The author
\end{doublespace}
\end{fullwidth}
}

\newcommand{\blankpage}{\newpage\hbox{}\thispagestyle{empty}\newpage} % Command to insert a blank page

\usepackage{makeidx} % Used to generate the index
\makeindex % Generate the index which is printed at the end of the document

%----------------------------------------------------------------------------------------
%	BOOK META-INFORMATION
%----------------------------------------------------------------------------------------

\title{Kinematically\\
		 Constrained\\
         Dense 3D SLAM} % Title of the book

\author{Matthew Klingensmith} % Author

%\publisher{Publisher Name} % Publisher

%----------------------------------------------------------------------------------------

\begin{document}

\frontmatter

%----------------------------------------------------------------------------------------
%	EPIGRAPH
%----------------------------------------------------------------------------------------

% \thispagestyle{empty}
% \openepigraph{Quotation 1}{Author, {\itshape Source}}
% \vfill
% \openepigraph{Quotation 2}{Author}
% \vfill
% \openepigraph{Quotation 3}{Author}

%----------------------------------------------------------------------------------------

\maketitle % Print the title page

%----------------------------------------------------------------------------------------
%	COPYRIGHT PAGE
%----------------------------------------------------------------------------------------

% \newpage
% \begin{fullwidth}
% ~\vfill
% \thispagestyle{empty}
% \setlength{\parindent}{0pt}
% \setlength{\parskip}{\baselineskip}
% Copyright \copyright\ \the\year\ \thanklessauthor
% 
% \par\smallcaps{Published by \thanklesspublisher}
% 
% \par\smallcaps{\url{http://www.bookwebsite.com}}
% 
% \par License information.\index{license}
% 
% \par\textit{First printing, \monthyear}
% \end{fullwidth}

%----------------------------------------------------------------------------------------

\tableofcontents % Print the table of contents

%----------------------------------------------------------------------------------------

\listoffigures % Print a list of figures

%----------------------------------------------------------------------------------------

\listoftables % Print a list of tables

%----------------------------------------------------------------------------------------
%	DEDICATION PAGE
%----------------------------------------------------------------------------------------

% \cleardoublepage
% ~\vfill
% \begin{doublespace}
% \noindent\fontsize{18}{22}\selectfont\itshape
% \nohyphenation
% Dedicated to my family and friends.
% \end{doublespace}
% \vfill
% \vfill

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\cleardoublepage
\chapter*{Introduction} % The asterisk leaves out this chapter from the table of contents
Dense 3D reconstruction is a well-studied problem in computer vision and
robotics. Given a series of noisy sensor readings a unknown poses, the task is
to infer the true geometric structure and color of the world. This  is a
variant of the Simultaneous Localization and Mapping (SLAM) problem, since it
requires simultaneously estimating the state of the sensor and the scene at
once. In the context of robotic manipulation, dense 3D reconstruction is useful for
scene understanding, planning, grasping, and more. 

Typical techniques for solving this problem focus on handheld sensors, and thus
assume that nothing is known about the pose of the sensor aside from weak
priors on the magnitude of the motion (though it is sometimes assumed that
other sources of motion estimation, such as markers, gyroscopes, or inertial
measurement units are available). For this reason, much prior work treats the
problem as unconstrained SLAM; where the pose of the sensor is mostly inferred
from the change in the map as it is built online. Depending on the type of
sensor, this can lead to severe pose drift over time.

Robots, on the other hand, often have sensors mounted on actuated linkages, such
as necks or arms. These linkages provide extremely strong priors on the motion
of the sensor, due to their constrained kinematics. Consider the case of a robot
with a hand-mounted 2D or 3D sensor. As the robot actuates its joints, the
sensor moves in a highly predictable manner. If the joint angles of the robot
are perfeclty known, and the robot is perfectly rigid, the problem of dense 3D
reconstruction becomes a simple mapping problem rather than a SLAM problem.

However, even kinematically constrained robotic linkages may have significant
noise and systematic inaccuracies.  Hysteresis from relative joint encoders
leads to inaccuracy that compounds over time; and on some systems, cable slack
and nonrigid deformation prevent the robot from knowing its kinematics with
certainty.  The \textit{Baxter} robot, for instance, has springy joints and
deformable plastic links which significantly increase its kinematic uncertainty.
The \textit{Barret WAM} robot arm is driven by cables, and has only relative
joint encoders. Stretch in the cables results in systematic error that is
configuration-dependant.

We can correct for this uncertainty using the sensor mounted on the arm. Rather
than estimating the pose of the sensor directly in the course of SLAM, we can
estimate the \textit{joint angles of the robot} instead; and hopefully arrive
at a better pose estimate this way. It is difficult to estimate the joint angles
of the robot instead of the pose of the sensor due mainly two factors:
first, there is a many-to-one mapping between joint angles and the pose of any
rigidly attached link, and second, the mapping is nonlinear. This mapping has
been studied extensively in robot motion planning and controls. By using
techniques from unconstrained 3D SLAM, and writing them in terms of the
configuration of the robot rather than direct 3D pose, we can track the pose of
the robot arm and map the world simultaneously. 

In particular, if a 3D (RGB-D or laser) sensor is used, 3D dense odometry
methods can be directly applied to the joint angles of the robot. We believe
that a simple mapping of the direct least-squares minimization technique made
popular by \textit{Kinect Fusion} exists by use of the robot manipulator's
Jacobian. Similarly, we believe that if only a 2D camera sensor is available,
techniques from visual odometry (which use camera-space motion of tracked image
features) can be applied to the robot's joint angles by use of the image
Jacobian. We plan to enable dense 3D reconstruction using hand-mounted sensors
on kinematically noisy robot arms using these techniques. 

\chapter{Background}
\section{3D Mapping and Localization}
\begin{itemize}
    \item Familiarize reader with the 3D mapping problem. Provide symbols.
    \item Talk about the difference between odometry and global localization.
    \item Discuss filtering.
    \item Discuss occupancy grids, point clouds, and the Truncated Signed
    Distance field
    \item A TSDf is a good idea to use in this context, because it implicitly
    contains gradient information.
    \item Kinect Fusion gracefully localizes and maps simultaneously using the
    TSDf as an objective function that informs the motion of the camera.
\end{itemize}

\section{Robot Kinematics and Arm Localization}
\begin{itemize}
    \item Robot linkages have well-defined kinematic constraints: joint limits,
    and rigid forward kinematics.
    \item When joint angles are known perfectly, the pose of any rigidly
    attached object on the body (including the sensor) is known.
    \item Nonrigid link deformation, hysterisis, and cable stretch can lead to
    incorrect forward kinematics. On some robots (such as \textit{Baxter} and
    some models of the \textit{Barret WAM}), this error is pronounced.
    \item When an external sensor is used (disconnected from the robot), one can
    track the configuration of the robot accurately.
    \item Tracking the configuration of the robot with an \textit{attached}
    sensor is less well studied -- though all visual servoing techniques
    implicitly have to solve this problem.
    \item A Kinect-Fusion-like algorithm can be used to simultaneously track the
    robot's configuration and map its environment.
\end{itemize}

\chapter{Framework}
\section{Mapping}
\subsection{Done So Far?}
\begin{itemize}
    \item Voxel carving
    \item Chisel
\end{itemize}
\subsection{To Do?}
\begin{itemize}
    \item Find a more principled way of dealing with noise in the TSDF, rather
    than averaging.
\end{itemize}
\section{Arm State Estimation}
\subsection{Done So Far?}
\begin{itemize}
    \item 3D Arm tracking with an external sensor.
    \item 2D experiments with gradient descent
\end{itemize}
\subsection{To Do?}
\begin{itemize}
    \item Lift the gradient descent to 3D.
    \item Test on several actual robots
    \item Explore alternative approaches to gradient descent.
    \item Explore the 2D visual odometry version of the problem.
    \item Model the joint angle uncertainty better, use this in a filter
    somehow?
\end{itemize}

\chapter{Research Questions}
\begin{itemize}
    \item In robotic arms, what is the typical uncertainty we should expect, and
    where does it come from?
    \item What benefit do we get out of using kinematically constrained dense
    odometry versus unconstrained dense odometry?
    \item Robot kinematics are underconstrained by sensor measurements, what
    pitfalls does this cause? How do we deal with this?
\end{itemize}

\chapter{Timeline}
\begin{itemize}
    \item Develop theory for kinematically constrained 3D visual odometry.
    \item Run experiments in 2D simulation to verify theory
    \item Run experiments in 3D simulation to verify theory
    \item Get 3D dense odometry working on the ADA arm with fake joint noise
    \item Attach a sensor to HERB's arm and do it with real noise.
    \item Attach a sensor to Abhinav's Baxter robot
    \item Extend theory to 2D visual odometry, and use Baxter's hand cam to
    localize it.
\end{itemize}
\backmatter

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\bibliography{bibliography} % Use the bibliography.bib file for the bibliography
\bibliographystyle{plainnat} % Use the plainnat style of referencing

%----------------------------------------------------------------------------------------

\printindex % Print the index at the very end of the document

\end{document}
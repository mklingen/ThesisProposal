%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tufte-Style Book (Minimal Template)
% LaTeX Template
% Version 1.0 (5/1/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
% IMPORTANT NOTE:
% In addition to running BibTeX to compile the reference list from the .bib
% file, you will need to run MakeIndex to compile the index at the end of the
% document.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{tufte-book} % Use the tufte-book class which in turn uses the tufte-common class

\hypersetup{colorlinks} % Comment this line if you don't wish to have colored links

\usepackage{microtype} % Improves character and word spacing

\usepackage{lipsum} % Inserts dummy text

\usepackage{booktabs} % Better horizontal rules in tables

\usepackage{graphicx} % Needed to insert images into the document
\graphicspath{{graphics/}} % Sets the default location of pictures
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio} % Improves figure scaling

\usepackage{fancyvrb} % Allows customization of verbatim environments
\fvset{fontsize=\normalsize} % The font size of all verbatim text can be changed here

\usepackage{xspace} % Used for printing a trailing space better than using a tilde (~) using the \xspace command

\newcommand{\blankpage}{\newpage\hbox{}\thispagestyle{empty}\newpage} % Command to insert a blank page
\newcommand{\apriori}{\textit{a. priori \xspace}}
\newcommand{\eg}{\textit{e. g.\xspace}}
\newcommand{\ie}{\texit{i. e\xspace}}
%----------------------------------------------------------------------------------------
%	BOOK META-INFORMATION
%----------------------------------------------------------------------------------------

\title{Kinematically\\
		 Constrained\\
         Dense 3D SLAM} % Title of the book

\author{Matthew Klingensmith} % Author

%\publisher{Publisher Name} % Publisher

%----------------------------------------------------------------------------------------

\begin{document}

\frontmatter

%----------------------------------------------------------------------------------------
%	EPIGRAPH
%----------------------------------------------------------------------------------------

% \thispagestyle{empty}
% \openepigraph{Quotation 1}{Author, {\itshape Source}}
% \vfill
% \openepigraph{Quotation 2}{Author}
% \vfill
% \openepigraph{Quotation 3}{Author}

%----------------------------------------------------------------------------------------

\maketitle % Print the title page

%----------------------------------------------------------------------------------------
%	COPYRIGHT PAGE
%----------------------------------------------------------------------------------------

% \newpage
% \begin{fullwidth}
% ~\vfill
% \thispagestyle{empty}
% \setlength{\parindent}{0pt}
% \setlength{\parskip}{\baselineskip}
% Copyright \copyright\ \the\year\ \thanklessauthor
% 
% \par\smallcaps{Published by \thanklesspublisher}
% 
% \par\smallcaps{\url{http://www.bookwebsite.com}}
% 
% \par License information.\index{license}
% 
% \par\textit{First printing, \monthyear}
% \end{fullwidth}

%----------------------------------------------------------------------------------------

\tableofcontents % Print the table of contents

%----------------------------------------------------------------------------------------

%\listoffigures % Print a list of figures

%----------------------------------------------------------------------------------------

%\listoftables % Print a list of tables

%----------------------------------------------------------------------------------------
%	DEDICATION PAGE
%----------------------------------------------------------------------------------------

% \cleardoublepage
% ~\vfill
% \begin{doublespace}
% \noindent\fontsize{18}{22}\selectfont\itshape
% \nohyphenation
% Dedicated to my family and friends.
% \end{doublespace}
% \vfill
% \vfill

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

%\cleardoublepage
\chapter*{Introduction}
Dense 3D reconstruction is a well-studied problem in computer vision and robotics. Given a series of noisy sensor readings a unknown poses, the task is to infer the true geometric structure and color of the world. This  is a variant of the Simultaneous Localization and Mapping (SLAM) problem, since it requires simultaneously estimating the state of the sensor and the scene at once. In the context of robotic manipulation, dense 3D reconstruction is useful for scene understanding, planning, grasping, and more.

Typical techniques for solving this problem focus on handheld sensors, and thus assume that little is known about the pose of the sensor aside from weak priors on the magnitude of the motion (though it is sometimes assumed that other sources of motion estimation, such as markers, gyroscopes, or inertial measurement units are available). For this reason, many prior works directly estimate the pose of a handheld sensor using visual (or depth) data alone.  Depending on the type of sensor, the lack of additional information can lead to inaccuracies in pose and ultimately  in the resulting 3D reconstruction. For instance, using a handheld RGB-D camera, it is impossible to detect motion parallel to a flat plane using the (unchanging) depth data alone, without additional sensors or \apriori knowledge of how the sensor moves.

Robots, on the other hand, often have sensors mounted on actuated linkages, such as necks or arms. These linkages provide extremely strong cues of the sensor's motion, due to their constrained kinematics. Consider the case of a robot arm with a hand-mounted 2D or 3D sensor. As the robot actuates its joints, the sensor moves in a predictable manner. If the joint angles of the robot are perfeclty known, and the robot is perfectly rigid, the pose of the sensor is known with absolute certainty, and the problem of dense 3D reconstruction becomes a simple mapping problem rather than a full SLAM problem.

However, even kinematically constrained robotic linkages may have significant noise and systematic inaccuracies. The use of relative joint encoders leads to inaccuracy that compounds over time; and on some systems, joint encoders are seperated from the actuation system by a mechanism with unpredictable dynamics.  The \textit{Baxter} robot, for instance, has series-elastic actuators and deformable plastic links which significantly increase its kinematic uncertainty. Another robot arm, the \textit{Barret WAM}, is driven by cables. Stretch in the cables results in systematic error that is configuration-dependant. In the extreme case, there may be degrees of freedom that are entirely unknown (such as the pose of the robot's base, or the extrinsic calibration of the sensor). One way of dealing with systematic error  is to calibrate the joint encoders to account for unknown dynamics and other sources of systematic error; but if additional unmodeled dynamics are introduced (such as a grasped object, or exterior forces),  the calibration will fail to capture them.

We can correct for uncertainty,  unmodeled and systematic error simultaneously by using a visual sensor in addition to the robot's joint encoders. If the sensor is mounted externally, so that all or part of the robot is visible, the problem becomes the well-studied \textit{articulated tracking} problem. In this case, the robot's known kinematic model can be used in conjunction with visual sensor data to directly estimate the robot's configuration. However, we are interested primarily in \textit{hand-mounted} sensors which, for the most part, cannot see the actuator on which they're mounted. In this case, we can't rely on a known model of the world to estimate the robot's configuration.

Rather than estimating the pose of the sensor directly in the course of SLAM, we can estimate the \textit{joint angles of the robot} instead; and hopefully arrive at a better pose estimate this way. It is difficult to estimate the joint angles of the robot instead of the pose of the sensor due mainly two factors: first, there is a many-to-one mapping between joint angles and the pose of any rigidly attached link, and second, the mapping is nonlinear. This mapping has been studied extensively in robot motion planning and controls. By using techniques from unconstrained 3D SLAM, and writing them in terms of the configuration of the robot rather than direct 3D pose, we can track the pose of the robot arm and map the world simultaneously.

In particular, if a 3D (RGB-D or laser) sensor is used, 3D dense odometry methods can be directly applied to the joint angles of the robot. We believe that a simple mapping of the direct least-squares minimization technique made popular by \textit{Kinect Fusion} exists by use of the robot manipulator's Jacobian. Similarly, we believe that if only a 2D camera sensor is available, techniques from visual odometry (which use camera-space motion of tracked image features) can be applied to the robot's joint angles by use of the image Jacobian. We plan to enable dense 3D reconstruction using hand-mounted sensors on kinematically noisy robot arms using these techniques.

\chapter{Background}
\section{3D Mapping and Localization}
\begin{itemize}
    \item Familiarize reader with the 3D mapping problem. Provide symbols.
    \item Talk about the difference between odometry and global localization.
    \item Discuss filtering.
    \item Discuss occupancy grids, point clouds, and the Truncated Signed
    Distance field
    \item A TSDf is a good idea to use in this context, because it implicitly
    contains gradient information.
    \item Kinect Fusion gracefully localizes and maps simultaneously using the
    TSDf as an objective function that informs the motion of the camera.
\end{itemize}

\section{Robot Arm Kinematics and Tracking}
\begin{itemize}
    \item Robot linkages have well-defined kinematic constraints: joint limits,
    and rigid forward kinematics.
    \item When joint angles are known perfectly, the pose of any rigidly
    attached object on the body (including the sensor) is known.
    \item Nonrigid link deformation, hysterisis, and cable stretch can lead to
    incorrect forward kinematics. On some robots (such as \textit{Baxter} and
    some models of the \textit{Barret WAM}), this error is pronounced.
    \item When an external sensor is used (disconnected from the robot), one can
    track the configuration of the robot accurately.
    \item Tracking the configuration of the robot with an \textit{attached}
    sensor is less well studied -- though all visual servoing techniques
    implicitly have to solve this problem.
    \item A Kinect-Fusion-like algorithm can be used to simultaneously track the
    robot's configuration and map its environment.
\end{itemize}

\chapter{Framework}
\section{Mapping}
\subsection{Done So Far?}
\begin{itemize}
    \item Voxel carving
    \item Chisel
\end{itemize}
\subsection{To Do?}
\begin{itemize}
    \item Find a more principled way of dealing with noise in the TSDF, rather
    than averaging.
\end{itemize}
\section{Arm State Estimation}
\subsection{Done So Far?}
\begin{itemize}
    \item 3D Arm tracking with an external sensor.
    \item 2D experiments with gradient descent
\end{itemize}
\subsection{To Do?}
\begin{itemize}
    \item Lift the gradient descent to 3D.
    \item Test on several actual robots
    \item Explore alternative approaches to gradient descent.
    \item Explore the 2D visual odometry version of the problem.
    \item Model the joint angle uncertainty better, use this in a filter
    somehow?
\end{itemize}

\chapter{Research Questions}
\begin{itemize}
    \item In robotic arms, what is the typical uncertainty we should expect, and
    where does it come from?
    \item What benefit do we get out of using kinematically constrained dense
    odometry versus unconstrained dense odometry?
    \item Robot kinematics are underconstrained by sensor measurements, what
    pitfalls does this cause? How do we deal with this?
\end{itemize}

\chapter{Timeline}
\begin{itemize}
    \item Develop theory for kinematically constrained 3D visual odometry.
    \item Run experiments in 2D simulation to verify theory
    \item Run experiments in 3D simulation to verify theory
    \item Get 3D dense odometry working on the ADA arm with fake joint noise
    \item Attach a sensor to HERB's arm and do it with real noise.
    \item Attach a sensor to Abhinav's Baxter robot
    \item Extend theory to 2D visual odometry, and use Baxter's hand cam to
    localize it.
\end{itemize}
\backmatter

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\bibliography{bibliography} % Use the bibliography.bib file for the bibliography
\bibliographystyle{plainnat} % Use the plainnat style of referencing

%----------------------------------------------------------------------------------------

%\printindex % Print the index at the very end of the document

\end{document}